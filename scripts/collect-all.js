/**
 * ç»Ÿä¸€æ•°æ®æŠ“å–å™¨
 * æ”¯æŒå¤šæ•°æ®æºï¼Œå¸¦é€Ÿç‡é™åˆ¶å’Œé”™è¯¯å¤„ç†
 */

const fs = require('fs');
const path = require('path');
const config = require('./config');

/**
 * å¸¦é€Ÿç‡é™åˆ¶çš„ fetch åŒ…è£…å™¨
 */
async function fetchWithRateLimit(url, options = {}, delay = 1000) {
  await new Promise(resolve => setTimeout(resolve, delay));

  const response = await fetch(url, {
    ...options,
    headers: {
      'Accept': 'application/json',
      'User-Agent': 'ASIP-Data-Collector/1.0',
      ...options.headers,
    },
  });

  // æ£€æŸ¥é€Ÿç‡é™åˆ¶
  const remaining = response.headers.get('X-RateLimit-Remaining');
  const reset = response.headers.get('X-RateLimit-Reset');

  if (remaining === '0') {
    const waitTime = (reset - Date.now() / 1000) * 1000;
    console.log(`âš ï¸ é€Ÿç‡é™åˆ¶ reachedï¼Œç­‰å¾… ${Math.ceil(waitTime / 1000)}s...`);
    await new Promise(resolve => setTimeout(resolve, Math.max(waitTime, 5000)));
  }

  return response;
}

/**
 * è·å– GitHub ä»“åº“çš„ README å†…å®¹
 */
async function getRepositoryReadme(owner, repo) {
  const url = `https://api.github.com/repos/${owner}/${repo}/readme`;

  try {
    const response = await fetchWithRateLimit(url, {
      headers: {
        'Accept': 'application/vnd.github.raw+json',
      },
    }, 500); // æ›´å¿«ä½†ä»æœ‰é™åˆ¶

    if (!response.ok) return null;

    const content = await response.text();
    return content;
  } catch (error) {
    return null;
  }
}

/**
 * GitHub æ•°æ®æŠ“å–å™¨ (æ—  Token ç‰ˆ)
 */
async function collectGitHub() {
  console.log('\nğŸ”„ å¼€å§‹ GitHub æ•°æ®é‡‡é›†...\n');

  const results = [];
  const seenUrls = new Set();

  for (const query of config.github.searchQueries) {
    console.log(`ğŸ“Š æœç´¢: "${query}"`);

    for (let page = 1; page <= config.github.maxPages; page++) {
      const url = `https://api.github.com/search/repositories?q=${encodeURIComponent(query)}+AI&sort=stars&order=desc&page=${page}&per_page=30`;

      try {
        const response = await fetchWithRateLimit(url, {}, config.github.rateLimitDelay);

        if (!response.ok) {
          console.log(`  âš ï¸  Page ${page}: ${response.status}`);
          break;
        }

        const data = await response.json();
        const repos = data.items || [];

        if (repos.length === 0) break;

        for (const repo of repos) {
          if (seenUrls.has(repo.html_url)) continue;
          seenUrls.add(repo.html_url);

          // åŸºæœ¬ä¿¡æ¯
          const projectData = {
            source: 'GitHub',
            source_type: 'repository',
            source_url: repo.html_url,
            project_name: repo.name,
            full_name: repo.full_name,
            description: repo.description,
            stars: repo.stargazers_count,
            forks: repo.forks_count,
            language: repo.language,
            topics: repo.topics || [],
            owner_type: repo.owner?.type,
            created_at: repo.created_at,
            updated_at: repo.updated_at,
            license: repo.license?.name,
            collected_at: new Date().toISOString(),
          };

          // è·å– README (é™åˆ¶å‰ 80 ä¸ªé¡¹ç›®ä»¥é¿å…è¶…æ—¶)
          if (results.length < 80) {
            const [owner, repoName] = repo.full_name.split('/');
            if (owner && repoName) {
              try {
                const readme = await getRepositoryReadme(owner, repoName);
                projectData.readme_content = readme ? readme.substring(0, 15000) : null;
                console.log(`    âœ“ ${repo.name}: ${readme ? 'README OK' : 'æ— '}`);
              } catch (e) {
                projectData.readme_content = null;
              }
              await new Promise(r => setTimeout(r, 600));
            }
          } else {
            projectData.readme_content = null;
          }

          results.push(projectData);
        }

        console.log(`  âœ“ Page ${page}: ${repos.length} repos`);

      } catch (error) {
        console.error(`  âœ— Error: ${error.message}`);
      }

      // éµå®ˆé€Ÿç‡é™åˆ¶
      await new Promise(resolve => setTimeout(resolve, 2000));
    }
  }

  console.log(`\nâœ… GitHub: å…±é‡‡é›† ${results.length} ä¸ªé¡¹ç›®`);
  return results;
}

/**
 * Hacker News æ•°æ®æŠ“å–å™¨
 */
async function collectHackerNews() {
  console.log('\nğŸ”„ å¼€å§‹ Hacker News æ•°æ®é‡‡é›†...\n');

  const results = [];
  const seenUrls = new Set();

  try {
    // è·å– top stories
    const topStoriesUrl = `${config.hackerNews.baseUrl}/topstories.json`;
    const response = await fetchWithRateLimit(topStoriesUrl, {}, config.hackerNews.rateLimitDelay);
    const storyIds = await response.json();

    const itemsToFetch = storyIds.slice(0, config.hackerNews.limit);

    for (let i = 0; i < itemsToFetch.length; i++) {
      const storyId = itemsToFetch[i];

      try {
        const itemUrl = `${config.hackerNews.baseUrl}/item/${storyId}.json`;
        const itemResponse = await fetchWithRateLimit(itemUrl, {}, 200);

        if (!itemResponse.ok) continue;

        const item = await itemResponse.json();

        // æ£€æŸ¥æ˜¯å¦åŒ…å« AI/Agent ç›¸å…³å…³é”®è¯
        const title = (item.title || '').toLowerCase();
        const isRelevant = config.hackerNews.searchQueries.some(
          q => title.includes(q.toLowerCase())
        );

        if (!isRelevant || seenUrls.has(item.url)) continue;
        seenUrls.add(item.url);

        if (item.url) {
          results.push({
            source: 'HackerNews',
            source_type: 'story',
            source_url: item.url,
            project_name: item.title,
            description: item.text || item.title,
            stars: item.score || 0,
            author: item.by,
            created_at: new Date(item.time * 1000).toISOString(),
            topics: ['HackerNews', 'è®¨è®º'],
            collected_at: new Date().toISOString(),
          });
        }

        if ((i + 1) % 10 === 0) {
          console.log(`  âœ“ Fetched ${i + 1}/${itemsToFetch.length}`);
        }

      } catch (error) {
        console.error(`  âš ï¸ Error fetching story ${storyId}: ${error.message}`);
      }

      await new Promise(resolve => setTimeout(resolve, 300));
    }

  } catch (error) {
    console.error(`  âœ— Hacker News Error: ${error.message}`);
  }

  console.log(`\nâœ… Hacker News: å…±é‡‡é›† ${results.length} ä¸ªé¡¹ç›®`);
  return results;
}

/**
 * Reddit æ•°æ®æŠ“å–å™¨ (ä½¿ç”¨ JSON API)
 */
async function collectReddit() {
  console.log('\nğŸ”„ å¼€å§‹ Reddit æ•°æ®é‡‡é›†...\n');

  const results = [];
  const seenUrls = new Set();

  for (const subreddit of config.reddit.subreddits) {
    console.log(`ğŸ“Š Subreddit: r/${subreddit}`);

    try {
      // ä½¿ç”¨ Reddit JSON API
      const url = `https://www.reddit.com/r/${subreddit}/hot.json?limit=50`;
      const response = await fetchWithRateLimit(url, {
        headers: {
          'Accept': 'application/json',
          'User-Agent': 'ASIP/1.0',
        },
      }, config.reddit.rateLimitDelay);

      if (!response.ok) {
        console.log(`  âš ï¸ Status: ${response.status}`);
        continue;
      }

      const data = await response.json();
      const posts = data.data?.children || [];

      for (const post of posts) {
        const p = post.data;

        // æ£€æŸ¥æ˜¯å¦åŒ…å« AI/Agent ç›¸å…³å†…å®¹
        const title = (p.title || '').toLowerCase();
        const isRelevant = config.reddit.searchQueries.some(
          q => title.includes(q.toLowerCase())
        );

        if (!isRelevant) continue;
        if (seenUrls.has(p.url)) continue;
        seenUrls.add(p.url);

        results.push({
          source: 'Reddit',
          source_type: 'post',
          source_url: `https://reddit.com${p.permalink}`,
          project_name: p.title.substring(0, 100),
          description: p.selftext || p.title,
          stars: p.score || 0,
          author: p.author,
          created_at: new Date(p.created_utc * 1000).toISOString(),
          topics: p.tags || ['Reddit', subreddit],
          num_comments: p.num_comments,
          collected_at: new Date().toISOString(),
        });
      }

      console.log(`  âœ“ Found ${results.length} relevant posts`);

    } catch (error) {
      console.error(`  âœ— Error: ${error.message}`);
    }

    await new Promise(resolve => setTimeout(resolve, 2000));
  }

  console.log(`\nâœ… Reddit: å…±é‡‡é›† ${results.length} ä¸ªé¡¹ç›®`);
  return results;
}

/**
 * ä¸»é‡‡é›†å‡½æ•°
 */
async function collectAll(sources = ['github', 'hackernews', 'reddit']) {
  console.log('='.repeat(50));
  console.log('ğŸš€ ASIP è‡ªåŠ¨åŒ–æ•°æ®é‡‡é›†å¼€å§‹');
  console.log('='.repeat(50));

  const allData = [];
  const timestamp = new Date().toISOString();

  // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
  const outputDir = path.join(__dirname, '../data/raw');
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  if (sources.includes('github')) {
    const githubData = await collectGitHub();
    allData.push(...githubData);
  }

  if (sources.includes('hackernews')) {
    const hnData = await collectHackerNews();
    allData.push(...hnData);
  }

  if (sources.includes('reddit')) {
    const redditData = await collectReddit();
    allData.push(...redditData);
  }

  // å»é‡
  const seen = new Set();
  const deduped = allData.filter(item => {
    const key = `${item.source}:${item.source_url}`;
    if (seen.has(key)) return false;
    seen.add(key);
    return true;
  });

  // ä¿å­˜åŸå§‹æ•°æ®
  const outputFile = path.join(outputDir, `raw_data_${timestamp.replace(/:/g, '-')}.json`);
  fs.writeFileSync(outputFile, JSON.stringify(deduped, null, 2));

  console.log('\n' + '='.repeat(50));
  console.log('ğŸ“Š é‡‡é›†ç»Ÿè®¡:');
  console.log(`   - æ€»è®¡: ${deduped.length} æ¡`);
  console.log(`   - GitHub: ${deduped.filter(d => d.source === 'GitHub').length}`);
  console.log(`   - Hacker News: ${deduped.filter(d => d.source === 'HackerNews').length}`);
  console.log(`   - Reddit: ${deduped.filter(d => d.source === 'Reddit').length}`);
  console.log(`\nğŸ’¾ å·²ä¿å­˜åˆ°: ${outputFile}`);
  console.log('='.repeat(50));

  return deduped;
}

// å¦‚æœç›´æ¥è¿è¡Œ
if (require.main === module) {
  const sources = process.argv.slice(2);
  collectAll(sources.length > 0 ? sources : ['github']).catch(console.error);
}

module.exports = { collectAll, collectGitHub, collectHackerNews, collectReddit };
